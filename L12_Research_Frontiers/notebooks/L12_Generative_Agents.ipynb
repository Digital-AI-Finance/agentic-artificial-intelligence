{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12: Generative Agents Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/agentic-artificial-intelligence/blob/main/L12_Research_Frontiers/L12_Generative_Agents.ipynb)\n",
    "\n",
    "Simplified demonstration of generative agent concepts from Park et al. (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q langchain-openai python-dotenv\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Memory Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Memory:\n",
    "    content: str\n",
    "    timestamp: str\n",
    "    importance: float = 5.0\n",
    "    \n",
    "class MemoryStream:\n",
    "    def __init__(self):\n",
    "        self.memories: List[Memory] = []\n",
    "    \n",
    "    def add(self, content: str, importance: float = 5.0):\n",
    "        self.memories.append(Memory(\n",
    "            content=content,\n",
    "            timestamp=datetime.now().strftime(\"%H:%M\"),\n",
    "            importance=importance\n",
    "        ))\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 5) -> List[Memory]:\n",
    "        # Simple recency + importance retrieval\n",
    "        scored = [(m, m.importance + (len(self.memories) - i) * 0.1) \n",
    "                  for i, m in enumerate(self.memories)]\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [m for m, _ in scored[:k]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generative Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenerativeAgent:\n",
    "    name: str\n",
    "    description: str\n",
    "    memory: MemoryStream = field(default_factory=MemoryStream)\n",
    "    \n",
    "    def perceive(self, observation: str):\n",
    "        \"\"\"Add observation to memory with importance scoring.\"\"\"\n",
    "        importance_prompt = f\"\"\"Rate importance of this observation for {self.name} (1-10):\n",
    "Agent description: {self.description}\n",
    "Observation: {observation}\n",
    "Return just the number.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            importance = float(llm.invoke(importance_prompt).content.strip())\n",
    "        except:\n",
    "            importance = 5.0\n",
    "        \n",
    "        self.memory.add(observation, importance)\n",
    "        print(f\"[{self.name}] Observed: {observation[:50]}... (importance: {importance:.1f})\")\n",
    "    \n",
    "    def reflect(self) -> str:\n",
    "        \"\"\"Generate high-level reflections from memories.\"\"\"\n",
    "        recent_memories = self.memory.retrieve(\"\", k=10)\n",
    "        memory_text = \"\\n\".join([m.content for m in recent_memories])\n",
    "        \n",
    "        prompt = f\"\"\"Based on these recent memories, generate a high-level insight for {self.name}.\n",
    "\n",
    "Agent: {self.description}\n",
    "Recent memories:\n",
    "{memory_text}\n",
    "\n",
    "What is a key insight or reflection?\"\"\"\n",
    "        \n",
    "        reflection = llm.invoke(prompt).content\n",
    "        self.memory.add(f\"Reflection: {reflection}\", importance=8.0)\n",
    "        return reflection\n",
    "    \n",
    "    def plan(self, goal: str) -> List[str]:\n",
    "        \"\"\"Generate a plan for achieving a goal.\"\"\"\n",
    "        relevant = self.memory.retrieve(goal, k=5)\n",
    "        context = \"\\n\".join([m.content for m in relevant])\n",
    "        \n",
    "        prompt = f\"\"\"Create a simple plan for {self.name} to achieve this goal.\n",
    "\n",
    "Agent: {self.description}\n",
    "Goal: {goal}\n",
    "Relevant context: {context}\n",
    "\n",
    "List 3-5 steps:\"\"\"\n",
    "        \n",
    "        response = llm.invoke(prompt).content\n",
    "        steps = [s.strip() for s in response.split('\\n') if s.strip()]\n",
    "        return steps[:5]\n",
    "    \n",
    "    def react(self, situation: str) -> str:\n",
    "        \"\"\"React to a situation based on personality and memories.\"\"\"\n",
    "        relevant = self.memory.retrieve(situation, k=3)\n",
    "        context = \"\\n\".join([m.content for m in relevant])\n",
    "        \n",
    "        prompt = f\"\"\"How would {self.name} react to this situation?\n",
    "\n",
    "Agent: {self.description}\n",
    "Relevant memories: {context}\n",
    "Situation: {situation}\n",
    "\n",
    "Describe their reaction briefly:\"\"\"\n",
    "        \n",
    "        return llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulate Agent Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent\n",
    "alice = GenerativeAgent(\n",
    "    name=\"Alice\",\n",
    "    description=\"A curious researcher interested in AI and machine learning. She is thoughtful and analytical.\"\n",
    ")\n",
    "\n",
    "# Add some initial memories\n",
    "alice.perceive(\"Started working on a new research project about language models\")\n",
    "alice.perceive(\"Had a great discussion with Bob about agent architectures\")\n",
    "alice.perceive(\"Read an interesting paper about generative agents\")\n",
    "alice.perceive(\"Noticed that multi-agent systems might be the future\")\n",
    "\n",
    "print(f\"\\nAlice has {len(alice.memory)} memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reflection\n",
    "reflection = alice.reflect()\n",
    "print(f\"\\nAlice's reflection:\\n{reflection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a plan\n",
    "plan = alice.plan(\"Write a paper about agent architectures\")\n",
    "print(\"\\nAlice's plan:\")\n",
    "for i, step in enumerate(plan, 1):\n",
    "    print(f\"  {i}. {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# React to a situation\n",
    "reaction = alice.react(\"A colleague asks for help debugging their agent code\")\n",
    "print(f\"\\nAlice's reaction:\\n{reaction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Demonstrated core generative agent concepts:\n",
    "- **Memory Stream**: Timestamped observations with importance\n",
    "- **Reflection**: High-level insights from memories\n",
    "- **Planning**: Goal-directed behavior generation\n",
    "- **Reaction**: Context-aware responses\n",
    "\n",
    "Full implementation would add: spatial awareness, social interactions, and emergent behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
