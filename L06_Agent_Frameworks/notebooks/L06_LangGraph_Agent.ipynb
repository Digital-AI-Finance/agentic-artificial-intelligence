{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Building Agents with LangGraph\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/agentic-artificial-intelligence/blob/main/L06_Agent_Frameworks/L06_LangGraph_Agent.ipynb)\n",
    "\n",
    "This notebook implements a stateful agent using LangGraph with:\n",
    "- Graph-based state machine architecture\n",
    "- Tool calling with conditional routing\n",
    "- Checkpointing for state persistence\n",
    "- Human-in-the-loop interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q langgraph langchain-openai langchain-anthropic python-dotenv\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "import operator\n",
    "\n",
    "# Load environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"LangGraph environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Tools\n",
    "\n",
    "Tools are functions the agent can call to interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use for calculations.\"\"\"\n",
    "    try:\n",
    "        # Safe eval for basic math\n",
    "        allowed = set('0123456789+-*/.() ')\n",
    "        if not all(c in allowed for c in expression):\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the knowledge base for information.\"\"\"\n",
    "    # Simulated knowledge base\n",
    "    knowledge = {\n",
    "        \"langgraph\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\",\n",
    "        \"autogen\": \"AutoGen is a framework for building multi-agent conversational systems.\",\n",
    "        \"react\": \"ReAct combines reasoning and acting in language model agents.\",\n",
    "    }\n",
    "    query_lower = query.lower()\n",
    "    for key, value in knowledge.items():\n",
    "        if key in query_lower:\n",
    "            return value\n",
    "    return \"No relevant information found.\"\n",
    "\n",
    "tools = [calculator, search_knowledge]\n",
    "print(f\"Defined {len(tools)} tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define State Schema\n",
    "\n",
    "The state schema defines what data flows through the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State schema for the agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    iteration_count: int\n",
    "\n",
    "# Messages use the 'add' reducer - new messages are appended\n",
    "# iteration_count tracks how many agent loops have executed\n",
    "print(\"State schema defined with messages and iteration_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Graph Nodes\n",
    "\n",
    "Nodes are functions that take state and return state updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM with tool binding\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"The agent node - calls LLM to decide next action.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    iteration = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    # Call LLM\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"iteration_count\": iteration + 1\n",
    "    }\n",
    "\n",
    "# Tool node handles tool execution\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"Agent and tool nodes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Routing Logic\n",
    "\n",
    "Conditional edges route based on the agent's decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine if agent should continue or end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    iteration = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    # Safety limit on iterations\n",
    "    if iteration >= 10:\n",
    "        return \"end\"\n",
    "    \n",
    "    # Check if LLM wants to call tools\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"end\"\n",
    "\n",
    "print(\"Routing logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Tools always return to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile with checkpointing\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Graph compiled successfully\")\n",
    "print(\"Nodes:\", list(app.nodes.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query: str, thread_id: str = \"default\"):\n",
    "    \"\"\"Run the agent with a query.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"iteration_count\": 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Stream events\n",
    "    for event in app.stream(initial_state, config):\n",
    "        for node_name, output in event.items():\n",
    "            print(f\"\\n[{node_name}]\")\n",
    "            if \"messages\" in output:\n",
    "                for msg in output[\"messages\"]:\n",
    "                    if hasattr(msg, \"content\") and msg.content:\n",
    "                        print(f\"  Content: {msg.content[:200]}...\" if len(str(msg.content)) > 200 else f\"  Content: {msg.content}\")\n",
    "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                        for tc in msg.tool_calls:\n",
    "                            print(f\"  Tool Call: {tc['name']}({tc['args']})\")\n",
    "    \n",
    "    # Get final state\n",
    "    final_state = app.get_state(config)\n",
    "    print(f\"\\nIterations: {final_state.values.get('iteration_count', 'N/A')}\")\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with calculation\n",
    "result = run_agent(\"What is 25 * 17 + 123?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with knowledge search\n",
    "result = run_agent(\"What is LangGraph and how does it differ from other frameworks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-step reasoning\n",
    "result = run_agent(\"First, search for what ReAct is. Then calculate 2^10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Examine Checkpoints\n",
    "\n",
    "LangGraph persists state at each step, enabling debugging and resumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get state history\n",
    "config = {\"configurable\": {\"thread_id\": \"default\"}}\n",
    "states = list(app.get_state_history(config))\n",
    "\n",
    "print(f\"\\nState history ({len(states)} checkpoints):\")\n",
    "for i, state in enumerate(states[:5]):  # Show last 5\n",
    "    print(f\"  {i+1}. Iteration: {state.values.get('iteration_count', 'N/A')}, \"\n",
    "          f\"Messages: {len(state.values.get('messages', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we implemented:\n",
    "1. **State Schema**: TypedDict with message history and iteration count\n",
    "2. **Nodes**: Agent node (LLM) and tool node (execution)\n",
    "3. **Edges**: Conditional routing based on tool calls\n",
    "4. **Checkpointing**: MemorySaver for state persistence\n",
    "\n",
    "Key patterns:\n",
    "- Graph cycles enable iterative refinement\n",
    "- State reducers control how updates merge\n",
    "- Checkpoints enable debugging and resumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
