{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9: Hallucination Detection and Verification\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/agentic-artificial-intelligence/blob/main/L09_Hallucination_Prevention/L09_Verification.ipynb)\n",
    "\n",
    "Implementing Chain-of-Verification and claim decomposition for hallucination detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q langchain-openai python-dotenv\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Claim Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_claims(text: str) -> List[str]:\n",
    "    \"\"\"Decompose text into atomic claims.\"\"\"\n",
    "    prompt = f\"\"\"Decompose this text into atomic, verifiable claims.\n",
    "Each claim should be a single fact that can be verified independently.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Return one claim per line, numbered.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    claims = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "    claims = [c.lstrip('0123456789.-) ') for c in claims]\n",
    "    return [c for c in claims if c]\n",
    "\n",
    "# Test\n",
    "test_text = \"\"\"Albert Einstein developed the theory of relativity in 1905. \n",
    "He was born in Germany and later became a US citizen. He won the Nobel Prize in Physics.\"\"\"\n",
    "\n",
    "claims = decompose_claims(test_text)\n",
    "for i, claim in enumerate(claims, 1):\n",
    "    print(f\"{i}. {claim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Verification Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verification_questions(claim: str) -> List[str]:\n",
    "    \"\"\"Generate questions to verify a claim.\"\"\"\n",
    "    prompt = f\"\"\"Generate 2-3 questions that, if answered correctly, would verify this claim.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Return one question per line.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    questions = [q.strip().lstrip('0123456789.-) ') for q in response.split('\\n') if q.strip()]\n",
    "    return [q for q in questions if q and '?' in q]\n",
    "\n",
    "# Test\n",
    "test_claim = \"Albert Einstein developed the theory of relativity in 1905\"\n",
    "questions = generate_verification_questions(test_claim)\n",
    "print(f\"Claim: {test_claim}\")\n",
    "print(\"Verification questions:\")\n",
    "for q in questions:\n",
    "    print(f\"  - {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Independent Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VerificationResult:\n",
    "    claim: str\n",
    "    is_verified: bool\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "\n",
    "def verify_claim_independently(claim: str, questions: List[str]) -> VerificationResult:\n",
    "    \"\"\"Verify claim by answering questions independently.\"\"\"\n",
    "    answers = []\n",
    "    for q in questions:\n",
    "        response = llm.invoke(f\"Answer factually: {q}\").content\n",
    "        answers.append((q, response))\n",
    "    \n",
    "    # Check consistency\n",
    "    check_prompt = f\"\"\"Based on these Q&A pairs, is the claim verified?\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Q&A:\n",
    "{chr(10).join([f'Q: {q} A: {a}' for q, a in answers])}\n",
    "\n",
    "Respond with:\n",
    "VERIFIED: [YES/NO]\n",
    "CONFIDENCE: [0.0-1.0]\n",
    "REASONING: [explanation]\"\"\"\n",
    "    \n",
    "    response = llm.invoke(check_prompt).content\n",
    "    \n",
    "    is_verified = \"YES\" in response.split(\"VERIFIED:\")[1].split(\"\\n\")[0].upper() if \"VERIFIED:\" in response else False\n",
    "    try:\n",
    "        confidence = float(response.split(\"CONFIDENCE:\")[1].split(\"\\n\")[0].strip())\n",
    "    except:\n",
    "        confidence = 0.5\n",
    "    reasoning = response.split(\"REASONING:\")[1].strip() if \"REASONING:\" in response else \"\"\n",
    "    \n",
    "    return VerificationResult(claim, is_verified, confidence, reasoning)\n",
    "\n",
    "# Test\n",
    "result = verify_claim_independently(test_claim, questions)\n",
    "print(f\"Verified: {result.is_verified}\")\n",
    "print(f\"Confidence: {result.confidence}\")\n",
    "print(f\"Reasoning: {result.reasoning[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Chain-of-Verification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_of_verification(text: str) -> Dict:\n",
    "    \"\"\"Complete Chain-of-Verification pipeline.\"\"\"\n",
    "    print(\"Step 1: Decomposing claims...\")\n",
    "    claims = decompose_claims(text)\n",
    "    \n",
    "    results = []\n",
    "    for i, claim in enumerate(claims[:5], 1):  # Limit for demo\n",
    "        print(f\"Step 2-3: Verifying claim {i}/{len(claims[:5])}...\")\n",
    "        questions = generate_verification_questions(claim)\n",
    "        result = verify_claim_independently(claim, questions)\n",
    "        results.append(result)\n",
    "    \n",
    "    verified_count = sum(1 for r in results if r.is_verified)\n",
    "    avg_confidence = sum(r.confidence for r in results) / len(results) if results else 0\n",
    "    \n",
    "    return {\n",
    "        \"total_claims\": len(claims),\n",
    "        \"verified_claims\": verified_count,\n",
    "        \"average_confidence\": avg_confidence,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "# Test with potential hallucination\n",
    "test_text = \"\"\"The Eiffel Tower was built in 1889 for the World's Fair.\n",
    "It is located in Berlin, Germany. Gustave Eiffel designed it.\"\"\"\n",
    "\n",
    "output = chain_of_verification(test_text)\n",
    "print(f\"\\nResults: {output['verified_claims']}/{output['total_claims']} verified\")\n",
    "print(f\"Average confidence: {output['average_confidence']:.2f}\")\n",
    "for r in output['results']:\n",
    "    status = 'Y' if r.is_verified else 'N'\n",
    "    print(f\"  [{status}] {r.claim[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Implemented Chain-of-Verification:\n",
    "1. **Claim Decomposition**: Break text into atomic facts\n",
    "2. **Question Generation**: Create verification questions\n",
    "3. **Independent Verification**: Answer without seeing original claim\n",
    "4. **Consistency Check**: Compare answers to original claim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
