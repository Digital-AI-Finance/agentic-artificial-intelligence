{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# L01: First Agent Implementation\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/agentic-artificial-intelligence/blob/main/L01_Introduction_Agentic_AI/notebooks/L01_first_agent.ipynb)\n\n**Week 1 - Introduction to Agentic AI**\n\n## Learning Objectives\n- Implement a basic ReAct agent from scratch\n- Understand the Thought-Action-Observation loop\n- Compare agent behavior vs standard LLM inference\n\n## Prerequisites\n- Python 3.11+\n- OpenAI API key or Anthropic API key\n- Basic understanding of LLM APIs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colab setup\nimport sys\nif 'google.colab' in sys.modules:\n    !pip install -q openai langchain langchain-openai python-dotenv\n    from google.colab import userdata\n    import os\n    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\nelse:\n    # Local setup - install if needed\n    # !pip install openai langchain langchain-openai python-dotenv\n    pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is set\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"Warning: OPENAI_API_KEY not found. Set it in .env file.\")\n",
    "else:\n",
    "    print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the ReAct Loop\n",
    "\n",
    "The ReAct paradigm (Yao et al., 2023) interleaves:\n",
    "- **Thought**: Reasoning about current state\n",
    "- **Action**: External operation\n",
    "- **Observation**: Feedback from environment\n",
    "\n",
    "```\n",
    "Trajectory: τ = (s₀, t₁, a₁, o₁, t₂, a₂, o₂, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ThoughtActionObservation:\n",
    "    \"\"\"Single step in a ReAct trajectory.\"\"\"\n",
    "    thought: str\n",
    "    action: str\n",
    "    action_input: str\n",
    "    observation: str\n",
    "\n",
    "@dataclass\n",
    "class AgentTrajectory:\n",
    "    \"\"\"Complete ReAct trajectory.\"\"\"\n",
    "    question: str\n",
    "    steps: List[ThoughtActionObservation]\n",
    "    final_answer: Optional[str] = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        output = f\"Question: {self.question}\\n\\n\"\n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            output += f\"Step {i}:\\n\"\n",
    "            output += f\"  Thought: {step.thought}\\n\"\n",
    "            output += f\"  Action: {step.action}[{step.action_input}]\\n\"\n",
    "            output += f\"  Observation: {step.observation}\\n\\n\"\n",
    "        if self.final_answer:\n",
    "            output += f\"Final Answer: {self.final_answer}\"\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Tools\n",
    "\n",
    "Our agent will have access to simple tools for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTool:\n",
    "    \"\"\"Base class for agent tools.\"\"\"\n",
    "    name: str = \"base_tool\"\n",
    "    description: str = \"Base tool\"\n",
    "    \n",
    "    def run(self, input_str: str) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SearchTool(SimpleTool):\n",
    "    \"\"\"Simulated search tool with predefined knowledge.\"\"\"\n",
    "    name = \"Search\"\n",
    "    description = \"Search for information. Input: search query.\"\n",
    "    \n",
    "    # Simulated knowledge base\n",
    "    knowledge = {\n",
    "        \"capital of france\": \"Paris is the capital of France.\",\n",
    "        \"capital of germany\": \"Berlin is the capital of Germany.\",\n",
    "        \"react paper\": \"ReAct was published by Yao et al. at ICLR 2023.\",\n",
    "        \"langchain\": \"LangChain is a framework for building LLM applications.\",\n",
    "        \"python\": \"Python is a programming language created by Guido van Rossum.\",\n",
    "        \"llm agent\": \"An LLM agent is an autonomous system that uses an LLM for reasoning.\",\n",
    "    }\n",
    "    \n",
    "    def run(self, input_str: str) -> str:\n",
    "        query = input_str.lower().strip()\n",
    "        for key, value in self.knowledge.items():\n",
    "            if key in query:\n",
    "                return value\n",
    "        return f\"No results found for: {input_str}\"\n",
    "\n",
    "class CalculatorTool(SimpleTool):\n",
    "    \"\"\"Simple calculator tool.\"\"\"\n",
    "    name = \"Calculator\"\n",
    "    description = \"Perform arithmetic. Input: math expression.\"\n",
    "    \n",
    "    def run(self, input_str: str) -> str:\n",
    "        try:\n",
    "            # Safe evaluation of simple math\n",
    "            allowed = set('0123456789+-*/(). ')\n",
    "            if all(c in allowed for c in input_str):\n",
    "                result = eval(input_str)\n",
    "                return str(result)\n",
    "            return \"Invalid expression\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "class FinishTool(SimpleTool):\n",
    "    \"\"\"Tool to signal task completion.\"\"\"\n",
    "    name = \"Finish\"\n",
    "    description = \"Use when you have the final answer. Input: the answer.\"\n",
    "    \n",
    "    def run(self, input_str: str) -> str:\n",
    "        return f\"FINISHED: {input_str}\"\n",
    "\n",
    "# Initialize tools\n",
    "TOOLS = {\n",
    "    \"Search\": SearchTool(),\n",
    "    \"Calculator\": CalculatorTool(),\n",
    "    \"Finish\": FinishTool(),\n",
    "}\n",
    "\n",
    "print(\"Available tools:\")\n",
    "for name, tool in TOOLS.items():\n",
    "    print(f\"  - {name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the ReAct Agent\n",
    "\n",
    "Now we'll build a simple ReAct agent that:\n",
    "1. Receives a question\n",
    "2. Generates thoughts and selects actions\n",
    "3. Executes actions and receives observations\n",
    "4. Iterates until reaching an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "REACT_PROMPT = \"\"\"You are a ReAct agent that solves problems by thinking step-by-step and using tools.\n",
    "\n",
    "Available tools:\n",
    "{tools}\n",
    "\n",
    "Use this format:\n",
    "Thought: reason about what to do next\n",
    "Action: tool_name[input]\n",
    "\n",
    "When you have the final answer, use:\n",
    "Thought: I now have the answer\n",
    "Action: Finish[your answer]\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {question}\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "def format_tools(tools: Dict[str, SimpleTool]) -> str:\n",
    "    \"\"\"Format tools for prompt.\"\"\"\n",
    "    return \"\\n\".join([f\"- {name}: {tool.description}\" for name, tool in tools.items()])\n",
    "\n",
    "def format_history(steps: List[ThoughtActionObservation]) -> str:\n",
    "    \"\"\"Format previous steps for context.\"\"\"\n",
    "    if not steps:\n",
    "        return \"\"\n",
    "    history = \"\"\n",
    "    for step in steps:\n",
    "        history += f\"\\nThought: {step.thought}\\n\"\n",
    "        history += f\"Action: {step.action}[{step.action_input}]\\n\"\n",
    "        history += f\"Observation: {step.observation}\\n\"\n",
    "    return history\n",
    "\n",
    "def parse_action(response: str) -> tuple[str, str, str]:\n",
    "    \"\"\"Parse LLM response to extract thought and action.\"\"\"\n",
    "    lines = response.strip().split('\\n')\n",
    "    thought = \"\"\n",
    "    action = \"\"\n",
    "    action_input = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('Thought:'):\n",
    "            thought = line[8:].strip()\n",
    "        elif line.startswith('Action:'):\n",
    "            action_str = line[7:].strip()\n",
    "            # Parse Action[input] format\n",
    "            if '[' in action_str and ']' in action_str:\n",
    "                action = action_str[:action_str.index('[')]\n",
    "                action_input = action_str[action_str.index('[')+1:action_str.rindex(']')]\n",
    "    \n",
    "    return thought, action, action_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAgent:\n",
    "    \"\"\"Simple ReAct agent implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: Dict[str, SimpleTool], max_steps: int = 5):\n",
    "        self.tools = tools\n",
    "        self.max_steps = max_steps\n",
    "    \n",
    "    def run(self, question: str, verbose: bool = True) -> AgentTrajectory:\n",
    "        \"\"\"Run the agent on a question.\"\"\"\n",
    "        trajectory = AgentTrajectory(question=question, steps=[])\n",
    "        \n",
    "        for step_num in range(self.max_steps):\n",
    "            # Build prompt with history\n",
    "            prompt = REACT_PROMPT.format(\n",
    "                tools=format_tools(self.tools),\n",
    "                question=question,\n",
    "                history=format_history(trajectory.steps)\n",
    "            )\n",
    "            \n",
    "            # Get LLM response\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=200,\n",
    "                temperature=0\n",
    "            )\n",
    "            \n",
    "            llm_output = response.choices[0].message.content\n",
    "            thought, action, action_input = parse_action(llm_output)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n--- Step {step_num + 1} ---\")\n",
    "                print(f\"Thought: {thought}\")\n",
    "                print(f\"Action: {action}[{action_input}]\")\n",
    "            \n",
    "            # Execute action\n",
    "            if action in self.tools:\n",
    "                observation = self.tools[action].run(action_input)\n",
    "            else:\n",
    "                observation = f\"Unknown action: {action}\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Observation: {observation}\")\n",
    "            \n",
    "            # Record step\n",
    "            step = ThoughtActionObservation(\n",
    "                thought=thought,\n",
    "                action=action,\n",
    "                action_input=action_input,\n",
    "                observation=observation\n",
    "            )\n",
    "            trajectory.steps.append(step)\n",
    "            \n",
    "            # Check if finished\n",
    "            if action == \"Finish\":\n",
    "                trajectory.final_answer = action_input\n",
    "                break\n",
    "        \n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = ReActAgent(tools=TOOLS)\n",
    "\n",
    "# Test question\n",
    "question = \"What is the capital of France?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "trajectory = agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex question\n",
    "question = \"What is 25 * 4 + 100?\"\n",
    "print(f\"\\nQuestion: {question}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "trajectory = agent.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare: LLM vs Agent\n",
    "\n",
    "Let's compare the agent approach to direct LLM inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_llm(question: str) -> str:\n",
    "    \"\"\"Direct LLM inference without agent loop.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Compare approaches\n",
    "test_question = \"What framework was created for building LLM applications?\"\n",
    "\n",
    "print(\"Direct LLM Response:\")\n",
    "print(direct_llm(test_question))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nReAct Agent Response:\")\n",
    "trajectory = agent.run(test_question, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "### What we learned:\n",
    "1. **ReAct Loop**: Thought -> Action -> Observation\n",
    "2. **Agent = LLM + Tools + Loop**: The agent uses LLM for reasoning and tools for actions\n",
    "3. **Trajectory**: Complete record of agent's reasoning process\n",
    "\n",
    "### Key differences from direct LLM:\n",
    "- **Grounding**: Agent can access external information via tools\n",
    "- **Iteration**: Agent can refine its approach based on observations\n",
    "- **Transparency**: Trajectory shows reasoning process\n",
    "\n",
    "### Next steps:\n",
    "- Week 2: Advanced prompting (CoT, ToT)\n",
    "- Week 3: Real tool integration with MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extension Exercise (Optional)\n",
    "\n",
    "Try extending the agent:\n",
    "1. Add a new tool (e.g., WeatherTool, WikipediaTool)\n",
    "2. Implement error handling for failed tool calls\n",
    "3. Add a memory system to remember previous interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your extension code here\n",
    "# Example: Add a custom tool\n",
    "\n",
    "class DateTimeTool(SimpleTool):\n",
    "    \"\"\"Tool to get current date/time.\"\"\"\n",
    "    name = \"DateTime\"\n",
    "    description = \"Get current date and time. Input: 'now'.\"\n",
    "    \n",
    "    def run(self, input_str: str) -> str:\n",
    "        from datetime import datetime\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Add to tools\n",
    "TOOLS[\"DateTime\"] = DateTimeTool()\n",
    "\n",
    "# Test\n",
    "agent_extended = ReActAgent(tools=TOOLS)\n",
    "trajectory = agent_extended.run(\"What is the current date?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}