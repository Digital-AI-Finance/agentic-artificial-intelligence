{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: GraphRAG Implementation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Digital-AI-Finance/agentic-artificial-intelligence/blob/main/L08_GraphRAG_Knowledge/L08_GraphRAG.ipynb)\n",
    "\n",
    "This notebook demonstrates building a simple GraphRAG system with entity extraction and knowledge graph construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q langchain-openai networkx python-dotenv\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import networkx as nx\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entity and Relationship Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_and_relations(text: str) -> Dict:\n",
    "    \"\"\"Extract entities and relationships from text using LLM.\"\"\"\n",
    "    prompt = f\"\"\"Extract entities and relationships from this text.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Return JSON with:\n",
    "{{\n",
    "  \"entities\": [{{\"name\": \"...\", \"type\": \"PERSON|ORG|PRODUCT|CONCEPT\"}}],\n",
    "  \"relationships\": [{{\"source\": \"...\", \"target\": \"...\", \"relation\": \"...\"}}]\n",
    "}}\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    # Extract JSON from response\n",
    "    try:\n",
    "        start = response.find('{')\n",
    "        end = response.rfind('}') + 1\n",
    "        return json.loads(response[start:end])\n",
    "    except:\n",
    "        return {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "# Test\n",
    "sample_text = \"\"\"OpenAI released GPT-4 in March 2023. Sam Altman is the CEO of OpenAI. \n",
    "GPT-4 is a large language model that powers ChatGPT. Microsoft invested in OpenAI.\"\"\"\n",
    "\n",
    "result = extract_entities_and_relations(sample_text)\n",
    "print(\"Entities:\", result.get(\"entities\", []))\n",
    "print(\"Relations:\", result.get(\"relationships\", []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knowledge_graph(extraction_result: Dict) -> nx.DiGraph:\n",
    "    \"\"\"Build a NetworkX graph from extracted entities and relations.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add entities as nodes\n",
    "    for entity in extraction_result.get(\"entities\", []):\n",
    "        G.add_node(entity[\"name\"], type=entity.get(\"type\", \"UNKNOWN\"))\n",
    "    \n",
    "    # Add relationships as edges\n",
    "    for rel in extraction_result.get(\"relationships\", []):\n",
    "        G.add_edge(rel[\"source\"], rel[\"target\"], relation=rel[\"relation\"])\n",
    "    \n",
    "    return G\n",
    "\n",
    "G = build_knowledge_graph(result)\n",
    "print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(\"Nodes:\", list(G.nodes(data=True))[:5])\n",
    "print(\"Edges:\", list(G.edges(data=True))[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph-Based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_knowledge_graph(G: nx.DiGraph, query_entity: str, hops: int = 2) -> str:\n",
    "    \"\"\"Retrieve context from knowledge graph around a query entity.\"\"\"\n",
    "    if query_entity not in G:\n",
    "        return f\"Entity '{query_entity}' not found in graph.\"\n",
    "    \n",
    "    # Get subgraph within N hops\n",
    "    neighbors = set([query_entity])\n",
    "    for _ in range(hops):\n",
    "        new_neighbors = set()\n",
    "        for node in neighbors:\n",
    "            new_neighbors.update(G.predecessors(node))\n",
    "            new_neighbors.update(G.successors(node))\n",
    "        neighbors.update(new_neighbors)\n",
    "    \n",
    "    # Build context from subgraph\n",
    "    context_parts = []\n",
    "    for source, target, data in G.edges(data=True):\n",
    "        if source in neighbors and target in neighbors:\n",
    "            context_parts.append(f\"{source} {data.get('relation', 'related to')} {target}\")\n",
    "    \n",
    "    return \". \".join(context_parts)\n",
    "\n",
    "# Test query\n",
    "context = query_knowledge_graph(G, \"GPT-4\")\n",
    "print(f\"Context for 'GPT-4': {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphrag_answer(G: nx.DiGraph, query: str) -> str:\n",
    "    \"\"\"Answer query using GraphRAG approach.\"\"\"\n",
    "    # Extract key entity from query\n",
    "    entity_prompt = f\"What is the main entity in this question? Return just the entity name.\\nQuestion: {query}\"\n",
    "    main_entity = llm.invoke(entity_prompt).content.strip()\n",
    "    \n",
    "    # Get graph context\n",
    "    context = query_knowledge_graph(G, main_entity)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer_prompt = f\"\"\"Based on this knowledge graph context, answer the question.\n",
    "    \n",
    "Context: {context}\n",
    "Question: {query}\n",
    "\n",
    "If the context doesn't contain the answer, say so.\"\"\"\n",
    "    \n",
    "    return llm.invoke(answer_prompt).content\n",
    "\n",
    "# Test\n",
    "answer = graphrag_answer(G, \"Who created GPT-4?\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Entity Extraction**: LLM-based extraction of entities and relationships\n",
    "2. **Graph Construction**: Building NetworkX knowledge graph\n",
    "3. **Graph Retrieval**: Multi-hop traversal for context\n",
    "4. **GraphRAG Query**: Combining graph context with LLM generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.11.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
